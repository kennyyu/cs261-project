\documentclass[10pt,twocolumn]{article}

\usepackage{algorithm}
%\usepackage{moreverb}   
%\usepackage{longtable}
\usepackage{fancyhdr}
\usepackage{algorithmic}             
%\usepackage{algorithm}
%\usepackage{array}     
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{fullpage}
\usepackage{amsmath, amssymb, amsthm}
%\usepackage[framed,numbered,autolinebreaks,useliterate]{mcode}
%\usepackage{mathabx}

% my macros
\newcommand{\paren}[1]{\left({#1}\right)}
\newcommand{\bracket}[1]{\left[{#1}\right]}
\newcommand{\curly}[1]{\left\{{#1}\right\}}
\newcommand{\vecb}[1]{\mathbf{#1}}
\newcommand{\matb}[1]{\mathbf{#1}}
\newcommand{\V}[1]{\mathbf{#1}}
\newcommand{\m}[1]{\mathbf{#1}}
\newcommand{\inhomog}[1]{\widetilde{#1}}
\newcommand{\transpose}[1]{{#1}^\top}

\usepackage{float}

\usepackage[margin=0.7in]{geometry}

\title{{\bf Intrusion Detection using Parzen-Windows on Provenance Graph Statistics}}
\author{
    Kenny Yu\\
    Harvard University\\
    \href{mailto:kennyyu@college.harvard.edu}{\texttt{kennyyu@college.harvard.edu}}
  \and
    R. J. Aquino\\
    Harvard University\\
    \href{mailto:rjaquino@college.harvard.edu}{\texttt{rjaquino@college.harvard.edu}}
}
\date{CS261, Fall 2013}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ABSTRACT
%

\begin{abstract}
Provenance is data that describes how a digital artifact came to be in its current state. We hypothesize
that intrusions on a system leave behind anomalies in the lineage of digital artifacts.
We present an intrusion detection approach to find these anomalies by analyzing centrality metrics
on provenance graphs. We use a Parzen-Window approach (TODO CITE) on various provenance graph centrality metrics (TODO CITE)
to determine probability density estimates of normal behavior, and we use these density estimates to 
determine if an intrusion occurred. We used this approach to analyze {\em user-to-remote} (u2r) intrusions and 
{\em remote-to-local} (r2l) intrusions (TODO: include r2l?) from the 1998 DARPA Intrusion Detection data sets (TODO CITE) and 
achieved up to *TODO true positive rate for intrusions* accuracy in detecting
intrusions with only *TODO false positive rate for intrusions* accuracy. We also present future work
to extend our intrusion model to an online intrusion detection system.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCTION
%

\section{Introduction}

For as long as systems have existed, there have been malicious users that attempt to exploit vulnerabilities
in systems to gain unintended privileged access. As a result, system designers and 
administrators place a large effort in securing systems and preventing intrusions. However, intrusions
inevitably occur because of bugs or flaws within the system, and as a result, system administrators want to
have some automatic way of detecting these intrusions. 

Intrusions often leave behind digital artifacts, e.g., unusual output or log files, a process executed
with an unusual arguments or environment, unusual system call activity by a process. In addition to
unusual digital artifacts, we hypothesize that
intrusions also leave behind abnormalities
in the {\em provenance} of these digital artifacts, the lineage of how these digital artifacts were created.

Provenance is data that describes how digital artifacts
came to be in their current state. Provenance data is typically structured as a directed acyclic graph with
typed nodes and typed edges.
Nodes typically include processes and files, and edges are directed from nodes to their dependencies. For example,
process nodes have edges directed towards input file nodes and to the parent process's node, and
file nodes have edges directed towards previous versions of the file and to the nodes of the
processes that modified the file.

Existing intrusion detection systems (IDS) use provenance data only to a limited extent.
??? person analyzes
basic statistics on provenance graphs (e.g., number of nodes, number of edges, ... TODO) in order to facilitate
easier manual intrusion detection by a human (CITE WORK). Their work, however, does not present a way of using provenance
graph to automatically determine intrusions. Other systems use provenance data to determine the scope of an
intrusion. For example, Backtracker (CITE WORK) uses provenance graphs to build causality graphs of intrusions: once the
system has
determined an intrusion has occurred, the system follows the causality graph backwards determine the original source of the attack, and 
then it follows the causality graph forwards to determine all the objects tainted by the attack. However, the authors 
do not present a way of using provenance data to automatically detect intrusions.


>>> INSERT PROVENANCE GRAPH SMALL EXAMPLE HERE SHOWING DATA FLOW

In this paper, we present an approach to use provenance data to automatically detect intrusions. Intrusion
detection can be framed as a {\em novelty detection} problem, in which one attempts to decide whether
an unknown test pattern is produced by an underlying distribution corresponding to a training set
of normal patterns (CITE WORK). However, ???authors note that in the case of intrusion detection, novel
or abnormal patterns are typically difficult to obtain, and as a result, they present a {\em Parzen-Window} approach
for non-parametric density estimation. Using this technique, they obtain a high degree of success
in identifying various intrusion types (CITE WORK). Because obtaining abnormal patterns is difficult, 
we borrow their Parzen-Window approach to build models of normal behavior using 
various provenance graph statistics and graph centrality metrics, and we evaluate the success of this technique
on {\em user-to-local} (u2l) intrusions (intrusions that provide unauthorized access to local superuser (root) privileges),
and {\em remote-to-local} (r2l) intrusions (intrusions that provide unauthorized access from a remote machine).

The main contributions of this paper are the following:
\begin{enumerate}
\item Discuss which provenance graph statistics we chose to use, how we chose them, and why we chose them.
\item Analyze the Parzen-Window technique with various provenance graph statistics on a real intrusion detection data set and evaluate its accuracy.
\item Discuss the limitations of the approach and present future work to transform the technique into an online intrusion detection system.
\end{enumerate}

POSSIBLY INCLUDE THIS
* the papers suck at finding u2r
* because they don't look at provenance graph structure
* we can do better?


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RELATED WORK
%

\section{Related Work}

\subsection{Existing IDSs using Provenance}

Many existing intrusion detection systems use provenance in some limited capacity; however, none of them
have used provenance for a fully automated detection system. 
Somayaji and Forrest's work in analyzing sequences of system calls for intrusion detection (CITE WORK) can
be seen as one of the earliest works in building an intrusion detection system using provenance: sequences of
system calls can be seen as a limited form of provenance, as many systems build provenance graphs from
system call traces (CITE SPADE AND BURRITO). By analyzing the sequences
of system calls a process makes over time, their system builds a profile of ``normal" process behavior. When
the process in the future makes enough patterns of unrecognized sequences of system calls, the system flags
this process as behaving abnormally and attempts to stop the process, either through exponentially slowing down
system calls or aborting system calls entirely. Notably, their system is trained only by analyzing ``normal" data
without knowing explicitly what is considered ``abnormal." Because their system achieves high
accuracy in determining intrusions with only sequences of system calls, we believe that having real provenance
data in a graph structure--which in theory would be a superset of system call data--would allow us
to achieve comparable, if not better intrusion detection accuracy.

More recent work make use of the structure of provenance as a directed graph for a semi-automatic form
of intrusion detection, and to determine the scope of an intrusion. ??? developed Backtracker (CITE) a modified
Linux kernel that tracks dependencies between operating system objects (files, processes, file names) similar
to provenance graphs. Backtracker builds a backwards causal graph to determine the entry point of an intrusion,
and it builds a forward causal graph to determine possibly tainted files, processes, or hosts in a distributed
system. However, Backtracker does not provide a way of automatically determining if an intrusion occurred
using provenance data; the provenance graph structure is only utilized after-the-fact.

??? make use of simple provenance graph statistics to categorize provenance graphs and to assist a human
in manual intrusion-detection. Given a data set of many provenance graphs, they calculated basic statistics
on the graphs (e.g., total nodes, total edges, max incoming edges on a node, max outgoing edges on a node,
node/edge ratio, average total edges per node, etc.). Their approach allows a human to more easily
notice anomalies in provenance graphs, but they do not provide a way to automate this detection.
We borrow their ideas of using simple provenance graph statistics as features to detect intrusions.

These works demonstrate that provenance data is indeed useful in collecting information about intrusions, and
Somayaji and ???'s work suggests that it might be possible to build a fully automated intrusion detection
system by making use of the graph structure of provenance.

\subsection{Parzen-Windows}

To address the difficulty of obtaining abnormal patterns for novelty detection on intrusion detection, we borrow
the Parzen-Window model approach proposed by ???.
??? person attempt to solve the lack of abnormal patterns problem by using Parzen-Windows to build {\em nonparametric}
density estimations of normal behavior (CITE). A density estimation is considered {\em nonparametric} if the estimation
makes no assumptions about the forms of the PDFs, except that PDFs are smooth. By using a nonparametric
density estimation, one can build a probability density estimate of normal behavior by only having examples of normal
behavior and no examples of abnormal behavior.

A {\em Parzen-window} estimate of a probability density function $p(\m{x})$
based on $n$ examples in a dataset $D$ drawn from model $\mathcal{M}$ is given by:
$$p(\m{x}) = \frac{1}{n} \sum_{i=1}^n \delta_n (\m{x} - \m{x_i})$$
where $\delta_n(\cdot)$ is a kernel function. They chose to use radially-symmetric Gaussian kernel functions because
Gaussian functions are smooth and therefore $p(\m{x})$ will be smooth, and because a radially-symmetric Gaussian function
can be specified by a single parameter, the variance of the kernel. Using a common variance $\sigma^2$ for all
the Gaussian kernels, we can rewrite $p(\m{x})$ as:
$$p(\m{x}) = \frac{1}{n(2\pi)^{d/2} \sigma^d} \sum_{i=1}^n  \exp \left\{  - \frac{|| \m{x} - \m{x_i}||^2}{2 \sigma^2}  \right\}$$
where $d$ is the dimensionality of the feature space $\m{x}$.

Let $\omega_1$ denote the state of being normal and $\omega_0$ the state of being abnormal.
To test if an example $\m{x} \in \omega_1$, they reframe the problem using hypothesis testing. Let $\m{y}$ be
an arbitrary example from $D$ drawn from $\mathcal{M}$, and let 
$$L(\m{y}) = \log p(\m{y})$$
be the log-likelihood of $\m{y}$ with respect to $\mathcal{M}$. Then we test the hypothesis that
$L(\m{x})$ is drawn from the distribution of the log-likelihood of the random examples in $D$ with:
\begin{eqnarray*}
P(L(\m{y}) \leq L(\m{x})) 
&=&  \frac{\#\m{y} \mbox { with } L(\m{y}) \leq L(\m{x})}{n} \\
&>& \psi
\end{eqnarray*}
for some threshold $0 < \psi < 1$, called the {\em false detection rate}. 
Thus, $\m{x} \in \omega_1$ is behaving normally if and only if $P(L(\m{y}) \leq L(\m{x})) > \psi$. 

In this paper, we use this same model to build profiles of ``normal" behavior for each process. We use
one-dimensional feature vectors $x$, and we use various provenance graph statistics and graph
centrality metrics as our features. We describe the various statistics and graph centrality metrics we explored
in the following section. For the common variance of our Gaussian kernels, we chose
the variance to be the variance of the data set $D$ for each unique process name. 
We vary the features we used and values of $\psi$ and evaluate its performance on an intrusion detection data set.

\subsection{Provenance Graph Features}

We were inspired by the work proposed by ??? who use simple provenance graph statistics to aide
in manual intrusion detection by humans. We extend their idea to make use of the typed node and typed edge
nature of provenance graphs. (CITE) For example, instead of simply counting number of edges from a node, we
counted number of edges of type {\em input} directed towards {\em file} type nodes, or the number of {\em fork}
edges from {\em process} type nodes. Below is the list of simple provenance graph statistics we used:
\begin{enumerate}
\item number of input and output files
\item number of input and output processes
\item number of input and output pipes
\item number of versions stemming from this node
\end{enumerate}

Furthermore, we hypothesize that intrusions manifest as anomalies in the lineage of digital artifacts, and
one way of observing this is through {\em graph centrality metrics}. A {\em graph centrality metric} is a function
of a node and its containing graph, and intuitively represents how {\em central} or {\em important} the node
is in the graph. In terms of provenance graphs, processes of the same program typically behave similarly to one another
and this should result in similar number of inputs, outputs, number of ancestors, and number of descendants for normal
process nodes of the same program.
Intrusions typically change the number of expected inputs and outputs (e.g., a process forking a shell process
when it normally does not), and we hypothesize that this can manifest as unusual changes in centrality
for the offending node in the provenance graph. ??? note the following 3 observations unique to provenance graphs (CITE):
\begin{enumerate}
\item The ubiquity (importance) of a node is a function of a node's descendants, not its ancestors. (Note: Because edges in provenance graphs are in the direction of data dependence instead of data flow, ``descendants" in this case means ancestors in the provenance graph).
\item There is no agreed-upon granularity in which provenance should be captured.
\item Provenance has a temporal component.
\end{enumerate}

Using these observations, they propose several centrality metrics on provenance graphs:
\begin{itemize}
\item \textbf{In-degree Centrality}. Because a node's importance is based on its output descendants, then the number of times a node was used as input to another node indicates a simple measure of importance.
\item \textbf{Age}. They note that large "jumps" in timestamps or age might indicate breaks between tasks, but this interpretation is complicated when scripts execute tasks in short succession.
\item \textbf{Ancestor Centrality}. This measures the total number of descendants of a node, normalized by the total number of nodes in a graph.
\item \textbf{Opsahl's Closeness Centrality}. This accounts for the number of edges between a node and its descendants. To compute this, we calculate
$$CC'(v) = \sum_{x \in V -  \{v\}} (d'_{xv})^{-1}$$
where $V$ is the set of nodes in the graph, $d'_{xv}$ is the distance from node $x$ to $v$ by only following outgoing edges from $x$. Unreachable nodes from $x$ will have $d'_{xv} = \infty$, and so $(d'_{xv})^{-1} = 0$.
\item \textbf{Provenance Eigenvector Centrality}. The centrality of the nodes is given by the left dominant eigenvector of the matrix:
$$M_{ij} =
\begin{cases}
1 & \text{if there is an edge } i \to j \\
1/|V| & \text{if there is no out edge from } i \\
0 & \text{otherwise}
\end{cases}
$$
\end{itemize}
We implemented some of these graph centrality metrics and used Parzen-Windows on centrality measurements to compute density estimates for each process.

\subsection{Intrusion Types}

The DARPA Intrusion Detection Data Sets (CITE) describe various kinds of intrusions in a network, including:
\begin{enumerate}
\item {\bf Denial of Service (dos)}. Intrusion that results in denial of service, e.g., overwhelming a server.
\item {\bf Remote to Local (r2l)}. Unauthorized access from a machine, e.g., guessing passwords.
\item {\bf User to Root (u2l)}. Unauthorized access to local superuser (root) privileges, e.g., various buffer overflow attacks.
\item {\bf Probing (probe)}. Surveillance and scanning, e.g. port scanning.
\end{enumerate}
Because we only collect provenance graphs local to the machine, we chose to limit our intrusion detection system only to u2l intrusions within this paper, as the other types of attacks involve exploiting the network and would not appear in provenance data.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DESIGN
%

\section{Design and Implementation}

\subsection{Selecting Metrics}

talk about PASS and SPADE here.

put that table here

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EVALUATION
%

\section{Evaluation}

\subsection{Experimental Setup}

\subsection{Results}

\subsection{Discussion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONCLUSION
%

\section{Conclusion}

\section{Limitations \& Future Work}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ACKNOWLEDGEMENTS
%

\section{Acknowledgements}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAPHY
%

\begin{thebibliography}{99}

\bibitem{fuzzy}
\textsc{Cao, D., Qiu, M., Chen, Z., Hu, F., Zhu, Y., and Wang, B.} Intelligent Fuzzy Anomaly Detection of Malicious Software. In {\em Internal Journal of Advanced Intelligence}, vol. 4, no. 1, pp 69-86 (December 2012).

\bibitem{somayaji-recent}
\textsc{Inoue, H. and Somayaji, A.} Lookahead Pairs and Full Sequences: A Tale of Two Anomaly Detection Methods. In {\em 2nd Annual Symposium on Information Assurance} (June 2007). 

\bibitem{backtracker}
\textsc{King, S. T. and Chen, P. M.} Backtracking Intrusions. In {\em SOSP'03 Proceedings of the nineteenth ACM symposium on Operating systems principles} (December 2003).

\bibitem{multihost}
\textsc{King, S. T., Mao Z. M., Lucchetti, D. G., and Chen, P. M.} Enriching intrusion alerts through multi-host causality. In {\em Proceedings of the 2005 Network and Distributed System Security Symposium} (February 2005).

\bibitem{fileprefetch}
\textsc{Lei, H. and Duchamp, D.} An Analytical Approach to File Prefetching. In {\em Proceedings of the USENIX 1997 Annual Technical Conference} (January 1997).

\bibitem{clustering}
\textsc{Macko, P., Margo, D., Seltzer, M.} Local Clustering in Provenance Graphs (Extended Version). In {\em Proceedings of the 22nd ACM international conference on Conference on information \& knowledge management} (August 2013).

\bibitem{orbiter}
\textsc{Macko, P. and Seltzer, M.} Provenance Map Orbiter: Interactive Exploration of Large Provenance Graphs. In {\em TaPP'11 Proceedings of the 2nd conference on Theory and practice of provenance} (June 2011).

\bibitem{fileattributes}
\textsc{Margo, D., and Smogor, R.} Using Provenance to Extract Semantic File Attributes. In {\em TaPP'10 Proceedings of the 2nd conference on Theory and practice of provenance} (February 2010).

\bibitem{passv2}
\textsc{Muniswamy-Reddy, K., Braun, U., Holland, D. A., Macko, P., Maclean, D., Margo, D., Seltzer, M., and Smogor, R.} Layering in Provenance Systems. In {\em Proceedings of the 2009 USENIX Annual Technical Conference} (June 2009).

\bibitem{pass}
\textsc{Muniswamy-Reddy, K., Holland, D. A., Braun, U., and Seltzer, M.} Provenance-Aware Storage Systems. In {\em Proceedings of the 2006 USENIX Annual Technical Conference} (June 2006).

\bibitem{exploitdb}
\textsc{Offensive Security, Inc.} The Exploit Database. {\tt http://www.exploit-db.com}.

\bibitem{metasploit}
\textsc{Rapid 7 Inc.} Metasploit Framework. {\tt http://www.metasploit.com}.

\bibitem{somayaji}
\textsc{Somayaji, A. and Forrest, S.} Automated Response Using System-Call Delays. In {\em Proceedings of the 2000 USENIX Annual Technical Conference} (August 2000).

\bibitem{correlated-anomalies}
\textsc{Tariq, D., Baig, B., Gehani, A., Mahmood, S., Tahir, R., Aqil, A., and Zaffar, F.} Identifying the provenance of correlated anomalies. In {\em SAC'11 Proceedings of the 2011 ACM Symposium on Applied Computing} (March 2011).

\end{thebibliography}

\end{document}
